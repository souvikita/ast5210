{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction and setup \u00b6 This document is a guide to using the RH code during AST5210. We will be using the RH 1.5D version of the code, which also has online documentation . You are expected to run the code yourself, either on your personal computer or using the Institute's Linux machines. The documentation describes how to download, compile and install the code, but here are some quick instructions. RH 1.5D needs two external libraries: HDF5 (for the input/output) and MPI (for parallel processing). If you are using the Institute's Linux machines, they are already installed. If using your laptop, they are probably not installed. See instructions below for compiling in both cases. Installing in Linux machines at Institute \u00b6 SSH into a local machine (e.g. beehive) and load the intel compilers and hdf5 module Clone the RH repository Edit Makefile.config , change CC to mpiicc , F90C to ifort , LD to mpiicc , and HDF5_DIR to /astro/local/hdf5/1.10.1/intel Compile Here's a summary of the commands to do the above: $ ssh beehive beehive$ module load Intel_parallel_studio/2018 hdf5/Intel/1.10.1 beehive$ git clone https://github.com/ita-solar/rh.git beehive$ cd rh beehive$ nano Makefile.config beehive$ make -j8 beehive$ cd rh15d beehive$ make -j8 Installing in your personal computer \u00b6 This procedure may not work in Windows; it was only tested for Linux and MacOS . RH needs C and Fortran compilers with the OpenMPI and HDF5 (parallel build) libraries. Manual installation is possible, but not recommended for those not experienced in building Unix packages. The easiest way to install all the necessary compilers and libraries is through the miniconda or Anaconda Python distributions. If you don't have conda installed, download and install it first ( get the latest python 3.x versions ). The first step is making sure you have C and Fortran compilers installed. Most Linux machines already have this installed ( gcc and gfortran ); if not you can install them via conda: $ conda install -c conda-forge gfortran_linux-64 gcc If you are on a Mac, you can also install the compilers with conda: $ conda install -c conda-forge gfortran_osx-64 clang_osx-64 Once you have the compilers working, you need to the following: Install MPI and hdf5 from Anaconda Clone the RH repository Edit Makefile.config , change CC to mpicc , F90C to gfortran (or other, if you are using another Fortran compiler), LD to mpicc , and HDF5_DIR to $HOME/anaconda/ (edit if you have miniconda or Anaconda in a different location) Compile! (Make sure mpicc is the conda version) Here's a summary of the commands to do the above: $ conda install -c conda-forge openmpi hdf5 = 1 .10.4 = mpi_openmpi_hd93f08e_1005 $ git clone https://github.com/ita-solar/rh.git $ cd rh $ nano Makefile.config $ make -j8 $ cd rh15d $ make -j8 If you don't have git, you can download a zip file with RH instead. Installing Jupyter and helita for analysis of output \u00b6 The Jupyter notebook (and associated packages) will be necessary to follow the exercise notebooks and visualise the output of RH 1.5D. If you are using the Linux machines, Jupyter and all necessary packages are already installed. If you don't have it installed in your personal computer, you can again use Anaconda: $ conda install -c conda-forge jupyterlab ipywidgets ipympl widgetsnbextension xarray nodejs You will also need helita , a Python package that contains modules to load and visualise the output of RH 1.5D. To install it, you do: $ git clone https://github.com/ITA-solar/helita.git $ cd helita $ python setup.py install --user There is also a zip file if you don't have git. If installing in your personal computer, you need C and Fortran compilers (see above). For both the Institute machines and your own computer, you will need to activate the Jupyter widgets with: $ jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-matplotlib After that, you are ready to start jupyter lab: $ jupyter lab To test your installation and try out the RH 1.5D widgets, you can run the sample notebooks inside the rh/doc/notebooks directory. In the terminal, got to that directory and enter jupyter lab . You can also test the widget output of Jupyter by running the slab and transp radiative transfer visualisation widgets. These do not require any files from RH, and are based on the IDL xslab.pro and xtransp.pro routines. You can start them in Jupyter in the following way: % matplotlib widget from helita.sim import rh15d_vis rh15d_vis . slab () rh15d_vis . transp () Running Jupyter lab remotely from the Linux machines \u00b6 This step is optional. It is possible to not only run Jupyter in your own machine, but also having it running on a remote computer at set to display the notebook in your own web browser. This way you can combine the best of both worlds: use a powerful computer with large memory and disk space, but keep a responsive graphical interface in your own computer. (You don't even need to install jupyter or all the programs in your computer.) To to this using the Institute computers, you need to set up an ssh tunnel and configure your browser to connect to that address. Here's an example using the beehive machine: $ ssh beehive beehive$ module load python beehive$ jupyter lab --no-browser ( ... ) http://localhost:8888/?token = 5089680adec1040 You see above that when you start jupyter, you'll get a lot of output but most importantly a URL. Save that URL. It is unique for this session and you'll need it later. The above gets jupyter started, then you need to connect to it. For that, we will use an SSH tunnel. First, we need to be able to connect to beehive directly, so you need to change the ~/.ssh/config file in your own computer. Add the following to the file (if it doesn't exist, create it): Host beehive* ForwardX11 yes User username ProxyCommand ssh -XY username@login.astro.uio.no -W %h:%p And replace username by your own username (two locations). Then you run the following command in your computer to start the SSH tunnel: $ ssh -NL 9999 :localhost:8888 beehive This will map port 8888 on beehive to port 9999 on your computer. You then use the URL you got from jupyter, change 8888 into 9999, and enter it in your browser. Then you should see jupyter running on beehive . Using Jupyter for these exercises \u00b6 We will be using the Jupyter notebook to run Python code to work with RH. If you haven't used it, there are several tutorials you can read to familiarise yourself with it. RH has a few Jupyter notebooks that illustrate some visualisation routines. You can try them out interactively with your own runs of RH, but for most of the work here is is recommended that you start your own notebooks and type code as you go. In the first cell of all your notebooks it is recommended to keep all the necessary imports and other boilerplate code that you don't want to type often. The following cell should cover all your basic imports for these exercises: % matplotlib widget import numpy as np import matplotlib.pyplot as plt from helita.sim import rh15d , rh15d_vis In all the examples from now on, it is expected you have already ran the code above in your notebooks. This code uses the ipympl backend for matplotlib , which allows interactive figures inside notebooks but has some drawbacks. If you redo plots without clearing old figures or creating new figures, you may run into problems with disappearing plots or plots updating in a new cell. The recommended approach for creating plots in a new cell is the following: fig , ax = plt . subplots () ax . plot ( ... ) # or ax.imshow(...), or any other matplotib command In the above you need to replace \"...\" with your plot command. In subsequent cells, you should name figures and axes differently, e.g.: fig1 , ax1 = plt . subplots () Otherwise, you will be updating the plots in the previous cell. If you get stuck with a disappearing figure, or have too many open figures ( matplotlib will complain if you have more than 20), you can always close all of them: plt . close ( \"all\" )","title":"Introduction"},{"location":"#introduction-and-setup","text":"This document is a guide to using the RH code during AST5210. We will be using the RH 1.5D version of the code, which also has online documentation . You are expected to run the code yourself, either on your personal computer or using the Institute's Linux machines. The documentation describes how to download, compile and install the code, but here are some quick instructions. RH 1.5D needs two external libraries: HDF5 (for the input/output) and MPI (for parallel processing). If you are using the Institute's Linux machines, they are already installed. If using your laptop, they are probably not installed. See instructions below for compiling in both cases.","title":"Introduction and setup"},{"location":"#installing-in-linux-machines-at-institute","text":"SSH into a local machine (e.g. beehive) and load the intel compilers and hdf5 module Clone the RH repository Edit Makefile.config , change CC to mpiicc , F90C to ifort , LD to mpiicc , and HDF5_DIR to /astro/local/hdf5/1.10.1/intel Compile Here's a summary of the commands to do the above: $ ssh beehive beehive$ module load Intel_parallel_studio/2018 hdf5/Intel/1.10.1 beehive$ git clone https://github.com/ita-solar/rh.git beehive$ cd rh beehive$ nano Makefile.config beehive$ make -j8 beehive$ cd rh15d beehive$ make -j8","title":"Installing in Linux machines at Institute"},{"location":"#installing-in-your-personal-computer","text":"This procedure may not work in Windows; it was only tested for Linux and MacOS . RH needs C and Fortran compilers with the OpenMPI and HDF5 (parallel build) libraries. Manual installation is possible, but not recommended for those not experienced in building Unix packages. The easiest way to install all the necessary compilers and libraries is through the miniconda or Anaconda Python distributions. If you don't have conda installed, download and install it first ( get the latest python 3.x versions ). The first step is making sure you have C and Fortran compilers installed. Most Linux machines already have this installed ( gcc and gfortran ); if not you can install them via conda: $ conda install -c conda-forge gfortran_linux-64 gcc If you are on a Mac, you can also install the compilers with conda: $ conda install -c conda-forge gfortran_osx-64 clang_osx-64 Once you have the compilers working, you need to the following: Install MPI and hdf5 from Anaconda Clone the RH repository Edit Makefile.config , change CC to mpicc , F90C to gfortran (or other, if you are using another Fortran compiler), LD to mpicc , and HDF5_DIR to $HOME/anaconda/ (edit if you have miniconda or Anaconda in a different location) Compile! (Make sure mpicc is the conda version) Here's a summary of the commands to do the above: $ conda install -c conda-forge openmpi hdf5 = 1 .10.4 = mpi_openmpi_hd93f08e_1005 $ git clone https://github.com/ita-solar/rh.git $ cd rh $ nano Makefile.config $ make -j8 $ cd rh15d $ make -j8 If you don't have git, you can download a zip file with RH instead.","title":"Installing in your personal computer"},{"location":"#installing-jupyter-and-helita-for-analysis-of-output","text":"The Jupyter notebook (and associated packages) will be necessary to follow the exercise notebooks and visualise the output of RH 1.5D. If you are using the Linux machines, Jupyter and all necessary packages are already installed. If you don't have it installed in your personal computer, you can again use Anaconda: $ conda install -c conda-forge jupyterlab ipywidgets ipympl widgetsnbextension xarray nodejs You will also need helita , a Python package that contains modules to load and visualise the output of RH 1.5D. To install it, you do: $ git clone https://github.com/ITA-solar/helita.git $ cd helita $ python setup.py install --user There is also a zip file if you don't have git. If installing in your personal computer, you need C and Fortran compilers (see above). For both the Institute machines and your own computer, you will need to activate the Jupyter widgets with: $ jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-matplotlib After that, you are ready to start jupyter lab: $ jupyter lab To test your installation and try out the RH 1.5D widgets, you can run the sample notebooks inside the rh/doc/notebooks directory. In the terminal, got to that directory and enter jupyter lab . You can also test the widget output of Jupyter by running the slab and transp radiative transfer visualisation widgets. These do not require any files from RH, and are based on the IDL xslab.pro and xtransp.pro routines. You can start them in Jupyter in the following way: % matplotlib widget from helita.sim import rh15d_vis rh15d_vis . slab () rh15d_vis . transp ()","title":"Installing Jupyter and helita for analysis of output"},{"location":"#running-jupyter-lab-remotely-from-the-linux-machines","text":"This step is optional. It is possible to not only run Jupyter in your own machine, but also having it running on a remote computer at set to display the notebook in your own web browser. This way you can combine the best of both worlds: use a powerful computer with large memory and disk space, but keep a responsive graphical interface in your own computer. (You don't even need to install jupyter or all the programs in your computer.) To to this using the Institute computers, you need to set up an ssh tunnel and configure your browser to connect to that address. Here's an example using the beehive machine: $ ssh beehive beehive$ module load python beehive$ jupyter lab --no-browser ( ... ) http://localhost:8888/?token = 5089680adec1040 You see above that when you start jupyter, you'll get a lot of output but most importantly a URL. Save that URL. It is unique for this session and you'll need it later. The above gets jupyter started, then you need to connect to it. For that, we will use an SSH tunnel. First, we need to be able to connect to beehive directly, so you need to change the ~/.ssh/config file in your own computer. Add the following to the file (if it doesn't exist, create it): Host beehive* ForwardX11 yes User username ProxyCommand ssh -XY username@login.astro.uio.no -W %h:%p And replace username by your own username (two locations). Then you run the following command in your computer to start the SSH tunnel: $ ssh -NL 9999 :localhost:8888 beehive This will map port 8888 on beehive to port 9999 on your computer. You then use the URL you got from jupyter, change 8888 into 9999, and enter it in your browser. Then you should see jupyter running on beehive .","title":"Running Jupyter lab remotely from the Linux machines"},{"location":"#using-jupyter-for-these-exercises","text":"We will be using the Jupyter notebook to run Python code to work with RH. If you haven't used it, there are several tutorials you can read to familiarise yourself with it. RH has a few Jupyter notebooks that illustrate some visualisation routines. You can try them out interactively with your own runs of RH, but for most of the work here is is recommended that you start your own notebooks and type code as you go. In the first cell of all your notebooks it is recommended to keep all the necessary imports and other boilerplate code that you don't want to type often. The following cell should cover all your basic imports for these exercises: % matplotlib widget import numpy as np import matplotlib.pyplot as plt from helita.sim import rh15d , rh15d_vis In all the examples from now on, it is expected you have already ran the code above in your notebooks. This code uses the ipympl backend for matplotlib , which allows interactive figures inside notebooks but has some drawbacks. If you redo plots without clearing old figures or creating new figures, you may run into problems with disappearing plots or plots updating in a new cell. The recommended approach for creating plots in a new cell is the following: fig , ax = plt . subplots () ax . plot ( ... ) # or ax.imshow(...), or any other matplotib command In the above you need to replace \"...\" with your plot command. In subsequent cells, you should name figures and axes differently, e.g.: fig1 , ax1 = plt . subplots () Otherwise, you will be updating the plots in the previous cell. If you get stuck with a disappearing figure, or have too many open figures ( matplotlib will complain if you have more than 20), you can always close all of them: plt . close ( \"all\" )","title":"Using Jupyter for these exercises"},{"location":"CaII_formation/","text":"Formation of Ca II lines \u00b6 In this exercise we will explore the formation of Ca II lines. First, we will work with different model atoms, and adjust the atoms.input file accordingly. Working with different atom files \u00b6 We've seen before that atoms can be either PASSIVE or ACTIVE . ACTIVE means they will be treated in full non-LTE, while PASSIVE are only included in background opacity calculations if their transitions are covered by a wavelength used in the calculations (determined by the ACTIVE atoms). For completeness, we will include a few large atoms as PASSIVE . Create a new atoms.input file with the following atom files: MgII-IRIS.atom CaII_PRD.atom Si.atom Al.atom Fe.atom He.atom N.atom Na.atom S.atom These are available in the ../../Atoms directory, so adjust the paths. Use LTE_POPULATIONS for all but the H, Ca II and Mg II atoms (use ZERO_RADIATION for these). The population file column can be left empty, but adjust the Nmetal value at the start of atoms.input . Set only CaII_PRD.atom as ACTIVE and run RH. Selecting wavelengths for detailed output \u00b6 Look at the output from the previous run. Chose a line of Ca II to work with (e.g. Ca II H or Ca II 854.2 nm). To examine the output in detail not all wavelengths are written to disk (to save space), so we must decide which ones to include. You will need to create a file ray.input that contains the indices of wavelengths to be saved. The indices of wavelengths are dependent on the model atoms and other input options, so it is handy to examine the previous run so you can identify the indices. For example, after loading the output into data , you can find the indices of 392.8 < \\lambda < < \\lambda < 394.0 by doing: data = rh15d . Rh15dout () wave = data . ray . wavelength indices = np . arange ( len ( wave ))[( wave > 392.8 ) & ( wave < 394.0 )] We want to save also the wavelength of 500 nm. To make sure it is actually calculated, you can do: wave . sel ( wavelength = 500 , method = 'nearest' ) and get its index with: index500 = np . argmin ( np . abs ( wave . data - 500 )) To save this into a file ray.input we do: f = open ( 'ray.input' , 'w' ) # this will overwrite any existing file! f . write ( '1.00 \\n ' ) output = str ( len ( indices ) + 1 ) for ind in indices : output += ' %i ' % ind output += ' %i \\n ' % index500 f . write ( output ) f . close () And now we run RH again! If you examine the output_ray.hdf5 with ncdump -h or h5dump -H you'll see that it contains several other arrays, such as chi and source function . We will work with these next. Calculating optical depths \u00b6 For the detailed output wavelengths, RH saves the monochromatic linear extinction coefficient (per length unit, variable chi ) but not the optical depth. We can obtain the optical depths by integrating chi over height. After you have run RH with detailed output and loaded the arrays, you can do: from scipy.integrate.quadrature import cumtrapz height = data . atmos . height_scale [ 0 , 0 ] . dropna ( 'height' ) # first column index500 = np . argmin ( np . abs ( data . ray . wavelength_selected - 500 )) # index of 500 nm tau500 = cumtrapz ( data . ray . chi [ 0 , 0 , :, index500 ] . dropna ( 'height' ), x =- height ) tau500 = np . concatenate ([[ 1e-20 ], tau500 ]) # ensure tau500 and height have same size Info In the above we make use of .dropna ( ' height ' ) , a method in xarray . This is only needed when you ran RH with the option 15D_DEPTH_ZCUT = TRUE . When TRUE , RH 1.5D will not include the top of the atmosphere, defined as where the temperature first reaches a temperature equal to 15D_TMAX_CUT , another option in keyword.input . The reasoning for this is to save computer time by removing depth points from the calculation, and prevent any numerical instabilities from large gradients when calculating lines formed in the photosphere or chromosphere. When 15D_DEPTH_ZCUT = TRUE , the output files will still have arrays that have all the depth points of the input atmosphere. RH 1.5D will write the missing points with a special fill value (typically 9.96921e+36), which xarray will interpret as NaN . Using .dropna ( ' height ' ) will cause xarray to exclude points with NaN from the calculations. Now you can plot \\tau_{500} \\tau_{500} vs height: fig , ax = plt . subplots () ax . plot ( height / 1e6 , tau500 ) # height in Mm Now you can answer the following: At what height does \\tau \\tau reach unity at 500 nm? What about in the core of your Ca II line? Plot the departure coefficients for the ground Ca II level on a height scale and on a \\tau_{500} \\tau_{500} scale Plot the \\tau \\tau =1 height as function of wavelength for the Ca II line Source function widget \u00b6 Now that your output files have the detailed output, you can use the SourceFunction widget from rh15d_vis : rh15d_vis . SourceFunction ( data ); And you can answer the following: At what height does the source function depart from the Planck function for the wings of the Ca II line? And at the line core?","title":"Formation of Ca II lines"},{"location":"CaII_formation/#formation-of-ca-ii-lines","text":"In this exercise we will explore the formation of Ca II lines. First, we will work with different model atoms, and adjust the atoms.input file accordingly.","title":"Formation of Ca II lines"},{"location":"CaII_formation/#working-with-different-atom-files","text":"We've seen before that atoms can be either PASSIVE or ACTIVE . ACTIVE means they will be treated in full non-LTE, while PASSIVE are only included in background opacity calculations if their transitions are covered by a wavelength used in the calculations (determined by the ACTIVE atoms). For completeness, we will include a few large atoms as PASSIVE . Create a new atoms.input file with the following atom files: MgII-IRIS.atom CaII_PRD.atom Si.atom Al.atom Fe.atom He.atom N.atom Na.atom S.atom These are available in the ../../Atoms directory, so adjust the paths. Use LTE_POPULATIONS for all but the H, Ca II and Mg II atoms (use ZERO_RADIATION for these). The population file column can be left empty, but adjust the Nmetal value at the start of atoms.input . Set only CaII_PRD.atom as ACTIVE and run RH.","title":"Working with different atom files"},{"location":"CaII_formation/#selecting-wavelengths-for-detailed-output","text":"Look at the output from the previous run. Chose a line of Ca II to work with (e.g. Ca II H or Ca II 854.2 nm). To examine the output in detail not all wavelengths are written to disk (to save space), so we must decide which ones to include. You will need to create a file ray.input that contains the indices of wavelengths to be saved. The indices of wavelengths are dependent on the model atoms and other input options, so it is handy to examine the previous run so you can identify the indices. For example, after loading the output into data , you can find the indices of 392.8 < \\lambda < < \\lambda < 394.0 by doing: data = rh15d . Rh15dout () wave = data . ray . wavelength indices = np . arange ( len ( wave ))[( wave > 392.8 ) & ( wave < 394.0 )] We want to save also the wavelength of 500 nm. To make sure it is actually calculated, you can do: wave . sel ( wavelength = 500 , method = 'nearest' ) and get its index with: index500 = np . argmin ( np . abs ( wave . data - 500 )) To save this into a file ray.input we do: f = open ( 'ray.input' , 'w' ) # this will overwrite any existing file! f . write ( '1.00 \\n ' ) output = str ( len ( indices ) + 1 ) for ind in indices : output += ' %i ' % ind output += ' %i \\n ' % index500 f . write ( output ) f . close () And now we run RH again! If you examine the output_ray.hdf5 with ncdump -h or h5dump -H you'll see that it contains several other arrays, such as chi and source function . We will work with these next.","title":"Selecting wavelengths for detailed output"},{"location":"CaII_formation/#calculating-optical-depths","text":"For the detailed output wavelengths, RH saves the monochromatic linear extinction coefficient (per length unit, variable chi ) but not the optical depth. We can obtain the optical depths by integrating chi over height. After you have run RH with detailed output and loaded the arrays, you can do: from scipy.integrate.quadrature import cumtrapz height = data . atmos . height_scale [ 0 , 0 ] . dropna ( 'height' ) # first column index500 = np . argmin ( np . abs ( data . ray . wavelength_selected - 500 )) # index of 500 nm tau500 = cumtrapz ( data . ray . chi [ 0 , 0 , :, index500 ] . dropna ( 'height' ), x =- height ) tau500 = np . concatenate ([[ 1e-20 ], tau500 ]) # ensure tau500 and height have same size Info In the above we make use of .dropna ( ' height ' ) , a method in xarray . This is only needed when you ran RH with the option 15D_DEPTH_ZCUT = TRUE . When TRUE , RH 1.5D will not include the top of the atmosphere, defined as where the temperature first reaches a temperature equal to 15D_TMAX_CUT , another option in keyword.input . The reasoning for this is to save computer time by removing depth points from the calculation, and prevent any numerical instabilities from large gradients when calculating lines formed in the photosphere or chromosphere. When 15D_DEPTH_ZCUT = TRUE , the output files will still have arrays that have all the depth points of the input atmosphere. RH 1.5D will write the missing points with a special fill value (typically 9.96921e+36), which xarray will interpret as NaN . Using .dropna ( ' height ' ) will cause xarray to exclude points with NaN from the calculations. Now you can plot \\tau_{500} \\tau_{500} vs height: fig , ax = plt . subplots () ax . plot ( height / 1e6 , tau500 ) # height in Mm Now you can answer the following: At what height does \\tau \\tau reach unity at 500 nm? What about in the core of your Ca II line? Plot the departure coefficients for the ground Ca II level on a height scale and on a \\tau_{500} \\tau_{500} scale Plot the \\tau \\tau =1 height as function of wavelength for the Ca II line","title":"Calculating optical depths"},{"location":"CaII_formation/#source-function-widget","text":"Now that your output files have the detailed output, you can use the SourceFunction widget from rh15d_vis : rh15d_vis . SourceFunction ( data ); And you can answer the following: At what height does the source function depart from the Planck function for the wings of the Ca II line? And at the line core?","title":"Source function widget"},{"location":"LTE_NLTE/","text":"LTE and non-LTE \u00b6 Populations and intensities \u00b6 In your run directory, change the atoms.input file so that the Ca is PASSIVE and the H atom is ACTIVE . In keyword.input set 15D_WRITE_POPS=TRUE so that the level populations are written. Leave everything else the same, run rh15d_ray go through the following tasks: Examine the output. Look at intensities of the H \\alpha \\alpha line Look at the level populations, and departure coefficients. Which level has the strongest departures? Now rename the output_ray.hdf5 file, e.g.: $ mv output/output_ray.hdf5 output/output_ray_NLTE.hdf5 Run RH again, but this time in LTE with rh15d_lteray . This is a special binary that only runs the problem in LTE. While normal rh15d_ray can write out both LTE and non-LTE populations, to obtain the LTE intensities you must run rh15d_lteray (which only writes output_ray.hdf5 , and no populations or any other output). Compare the H \\alpha \\alpha intensities in LTE and NLTE. What are the differences? Note that by default, rh15d.Rh15dout() will read the file named output_ray.hdf5 only. You can call it twice to make two objects, but make sure the second object does not load the same files by switching off the automatic read: fig , ax = plt . subplots () data1 = rh15d . Rh15dout () data2 = rh15d . Rh15dout ( autoread = False ) data2 . read_ray ( 'output_ray_NLTE.hdf5' ) data1 . ray . intensity . plot () data2 . ray . intensity . plot () Or you can just read the files directly with xarray: import xarray as xr data1 = xr . open_dataset ( \"output_ray.hdf5\" ) data2 = xr . open_dataset ( \"output_ray_NLTE.hdf5\" ) data1 . intensity . plot () data2 . intensity . plot () Initial solution \u00b6 In this part we will only do runs in NLTE. RH solves the radiative transfer equation in an iterative procedure, using the accelerated \\Lambda \\Lambda iteration to arrive at the final solution. How quickly it arrives at the final result depends on how good our initial estimate is. RH has different methods for this, and different atoms work better with different initial solutions. Let's experiment with the initial solution in a hydrogen atom. In atoms.input , you'll see that hydrogen has an initial solution of ZERO_RADIATION . Run rh15d_ray again and check how many iterations were necessary to achieve convergence. Plot the array data.mpi.delta_max_history (available when you load the output with rh15d.Rh15dout() ), which shows the convergence history: fig , ax = plt . subplots () data . mpi . delta_max_history . plot () Now change the H initial solution to LTE_POPULATIONS . How many iterations did it take? Compare the convergence plots with both initial solutions. Can you see the accelerated iterations? What is their period? Try running with no acceleration to see the result (set NG_ORDER=0 in keyword.input ). Info When you run RH 1.5D multiple times, the output files will be overwritten . If you want to save the results, it is recommended you copy the output*hdf5 files to a different directory. With the helita interface, you can load RH output from different directories by passing the directory name as argument to the Rh15dout call, e.g.: data1 = rh15d.Rh15dout() reads from current directory, while data2 = rh15d.Rh15dout('mydir/') reads the output from mydir/ .","title":"LTE and non-LTE"},{"location":"LTE_NLTE/#lte-and-non-lte","text":"","title":"LTE and non-LTE"},{"location":"LTE_NLTE/#populations-and-intensities","text":"In your run directory, change the atoms.input file so that the Ca is PASSIVE and the H atom is ACTIVE . In keyword.input set 15D_WRITE_POPS=TRUE so that the level populations are written. Leave everything else the same, run rh15d_ray go through the following tasks: Examine the output. Look at intensities of the H \\alpha \\alpha line Look at the level populations, and departure coefficients. Which level has the strongest departures? Now rename the output_ray.hdf5 file, e.g.: $ mv output/output_ray.hdf5 output/output_ray_NLTE.hdf5 Run RH again, but this time in LTE with rh15d_lteray . This is a special binary that only runs the problem in LTE. While normal rh15d_ray can write out both LTE and non-LTE populations, to obtain the LTE intensities you must run rh15d_lteray (which only writes output_ray.hdf5 , and no populations or any other output). Compare the H \\alpha \\alpha intensities in LTE and NLTE. What are the differences? Note that by default, rh15d.Rh15dout() will read the file named output_ray.hdf5 only. You can call it twice to make two objects, but make sure the second object does not load the same files by switching off the automatic read: fig , ax = plt . subplots () data1 = rh15d . Rh15dout () data2 = rh15d . Rh15dout ( autoread = False ) data2 . read_ray ( 'output_ray_NLTE.hdf5' ) data1 . ray . intensity . plot () data2 . ray . intensity . plot () Or you can just read the files directly with xarray: import xarray as xr data1 = xr . open_dataset ( \"output_ray.hdf5\" ) data2 = xr . open_dataset ( \"output_ray_NLTE.hdf5\" ) data1 . intensity . plot () data2 . intensity . plot ()","title":"Populations and intensities"},{"location":"LTE_NLTE/#initial-solution","text":"In this part we will only do runs in NLTE. RH solves the radiative transfer equation in an iterative procedure, using the accelerated \\Lambda \\Lambda iteration to arrive at the final solution. How quickly it arrives at the final result depends on how good our initial estimate is. RH has different methods for this, and different atoms work better with different initial solutions. Let's experiment with the initial solution in a hydrogen atom. In atoms.input , you'll see that hydrogen has an initial solution of ZERO_RADIATION . Run rh15d_ray again and check how many iterations were necessary to achieve convergence. Plot the array data.mpi.delta_max_history (available when you load the output with rh15d.Rh15dout() ), which shows the convergence history: fig , ax = plt . subplots () data . mpi . delta_max_history . plot () Now change the H initial solution to LTE_POPULATIONS . How many iterations did it take? Compare the convergence plots with both initial solutions. Can you see the accelerated iterations? What is their period? Try running with no acceleration to see the result (set NG_ORDER=0 in keyword.input ). Info When you run RH 1.5D multiple times, the output files will be overwritten . If you want to save the results, it is recommended you copy the output*hdf5 files to a different directory. With the helita interface, you can load RH output from different directories by passing the directory name as argument to the Rh15dout call, e.g.: data1 = rh15d.Rh15dout() reads from current directory, while data2 = rh15d.Rh15dout('mydir/') reads the output from mydir/ .","title":"Initial solution"},{"location":"MgII_formation/","text":"Formation of Mg II lines \u00b6 In this exercise we will explore the formation of Mg II lines. You should have completed (or understood) the previous Ca II example to work on this one. The objective of this exercise is to synthesise the spectral region corresponding to the NUV window of the IRIS spectrograph, including the Mg II lines but also the many blended lines. Setup \u00b6 In your run directory, we'll use almost the same setup as for the Ca II exercise. First, you need to modify atoms.input and set the MgII-IRIS.atom as ACTIVE (and all other atoms as PASSIVE ). Now, because we changed the active atom, the wavelengths written to file will be different. This means that the wavelength indices we previously wrote in ray.input no longer match what we expected. For simplicity, in this exercise we can use a simple ray.input that writes no extra output. You can create a ray.input file with only the following: 1.00 0 The Mg II h & k lines are formed under partial redistribution (PRD). PRD is a complex topic and is not taught in this introductory course. But for this exercise you only need to activate it in RH. In your keyword.input file, find the option PRD_N_MAX_ITER . This should be set to zero. Now change it to PRD_N_MAX_ITER = 3 , and you will activate PRD for atoms that require it. Now run rh15d_ray with that setup and look at the intensity in the region of 279 - 280.5 nm, where the Mg II lines are located. How many wavelength points does the intensity have? Wavelength files \u00b6 The wavelengths that RH 1.5D uses depend on the active model atoms. In the atom file you can configure the number of wavelength points that each transition has, as well as how they are distributed. For bound-bound transitions, the parameter Nlambda defines how many wavelength points they have. This is the most straightforward way to change the wavelength grid. In addition to changing the atom files, there is another mechanism to add more wavelengths: the wavelength files. These files contain a list of additional wavelengths for RH to calculate. They are useful when you want to add lines from lists (see below) that are not covered by the active atoms, when you want to add more wavelengths to a specific line or region, or when you want better control over the wavelength grid. Using wavelength files \u00b6 Only one wavelength file (or wavelength table) is allowed in RH. To use a wavelength file, you need to set the option WAVETABLE equal to the wavelength file. Edit your keyword.input file so that WAVETABLE = ../../Atoms/wave_files/IRIS_NUV_full.wave . This file contains a list of the IRIS NUV wavelengths, and if you've previously unpacked the archive rh_ast5210.tar.bz2 , it should be in that directory. Run rh15d_ray again with that new option. How many wavelength files were used now? You should also have noticed that the calculation took much longer now because it scales with the number of wavelengths. Reading and writing wavelength files \u00b6 The wavelength files are written in binary XDR format . In helita there are functions to read and write these files. Info The contents of the wavelength files should be in vacuum wavelengths, and in nm. RH uses vacuum wavelengths internally, although by default all the output for \\lambda \\lambda > 200 nm will be given in air wavelengths. To read an existing an existing wavelength file, use the function helita.sim.rh15d.read_wave_file : IRIS_wave = rh15d . read_wave_file ( '/Users/tiago/codes/rh/Atoms/wave_files/IRIS_NUV_full.wave' ) Now check the content of that IRIS wavelength file. What is the wavelength separation? To write a wavelength file, you use the function helita.sim.rh15d.make_wave_file : # this will write wavelenghts from 650 to 650 nm, 0.01 nm spacing rh15d . make_wave_file ( 'my.wave' , 650 , 660 , 0.01 ) # this will write an existing array \"my_waves\", if it exists rh15d . make_wave_file ( 'my.wave' , new_wave = my_waves ) By default, make_wave_file will assume your wavelengths are in air and convert to vacuum wavelengths. If you don't want this, use the option air=False . Create a new wavelength file with the same range of wavelengths as in the IRIS file, but with a spacing of 0.001 nm. We'll use this file in the exercises below. When you run with a large wavelength file, RH can take a long time to finish. How to check if RH is indeed running properly? In the run directory there is a subdirectory called scratch . Inside, you can find a lot of temporary scratch files ( *.dat ), and also log files ( rh_p*.log ). Each process writes its own log file. Because you've been running rh15d_ray with only one process, there should only be one file called rh_p0.log . This file is updated as RH is running. If RH is running and you want to check if it's actually doing anything, you can follow that file with tail: $ tail -f output/scratch/rh_p0.log Line lists \u00b6 Now that you've calculated the spectrum, you'll see that it only contains the lines of Mg II (the active atom). Adding extra wavelengths from the file does not change that. We'd like to make this as realistic as possible and include as many lines as possible. The most correct way to do this is to include atoms of relevant elements with all the necessary transitions and calculate all spectra in NLTE. Unfortunately, this would require a very large number of atoms and at least hundreds of thousands of transitions, requiring many wavelength points and RH 1.5D would probably not finish before you are done with AST5210. A simpler and much faster option is to calculate those lines in LTE and use a line list. Again, LTE is probably not a good approximation for many of the strong spectral lines, but this a tradeoff that we'll have to live with. A line list is a file with a list of bound-bound transitions and their parameters. RH supports line lists with the format of the Kurucz line lists . In this format, each line in the file is a different spectral line. The various columns have different atomic data, starting with wavelength, log gf, and element code (see Kurucz page for more details). To use a line list with RH, you will need to uncomment the setting KURUCZ_DATA = kurucz.input in keyword.input . This merely points to a text file (in this case we use kurucz.input ) that has a list of line list files. Uncomment that line, and edit the file kurucz.input . You can start by using only a single entry: ../../Atoms/Kurucz/gfMgIIhk_IRIS_full If you've previously unpacked the archive rh_ast5210.tar.bz2 , the file above should be in your RH directory. It contains 3714 lines that are present in the wavelength region 278.1745 - 283.4151 nm. Run rh15d_ray again with the line list, the wavelength file IRIS_NUV_full.wave and inspect the results. Run timings with the shell command time and see how much more time it takes to include the wavelength file, and both the line lists. Included in your rh/Atoms/Kurucz/ is another line list called gfMgIIhk_IRIS_full.trim_85 . This file containts a subset of the gfMgIIhk_IRIS_full . It was made to approximate the full line list but only keeping the strongest lines (around the 85 th percentile of line strength). Run with this new file and see if you can see a difference in the output intensity. You may notice that the extra lines do not appear very well resolved (e.g. triangular shapes). This is because the file IRIS_NUV_full.wave only has enough wavelength points to cover the spatial resolution of IRIS, and was not meant for detailed analysis of individual lines. Now run RH again but with the wavelength file you created (separation 0.001 nm), and see if the lines are better resolved now. How many wavelengths were calculated? \\tau \\tau =1 heights \u00b6 In the exercises above we are not saving detailed output, so we don't have the total absorption (chi) that is necessary to calculate the optical depth. However, even without detailed output it is possible to save an additional quantity that helps us diagnose approximately where the line is formed: the height where the optical depth reaches unity. In keyword.input you need to set 15D_WRITE_TAU1 = TRUE (it should not be enabled by default). Re-run RH and you'll find that the output_ray.hdf5 has an additional output variable called tau_one_height . The variable tau_one_height , just like intensity , is a function of wavelength. Plot it as a function of wavelength. You can also plot the intensity separately. Which line is formed higher? What is the difference in \\tau \\tau =1 height between the Mg II h & k lines with your model atmosphere? Aside from the Mg II lines, which other lines are formed higher? Putting it all together \u00b6 Now we'll put the above concepts together by applying them to the Ca II H line (air wavelength 396.847 nm): Run rh15d_ray using the CaII_PRD.atom as active atom (Mg II can be passive) Create a new wavelength file to adequately sample all the blending lines on the wings of Ca II H. Choose an appropriate spacing. Use the file rh/Atoms/Kurucz/gf0400.10 as a starting point to create a line list to cover the wavelength range of the Ca II H line. Just delete all the lines whose wavelengths are outside the range. Run RH with and without the new wavelengths/lines in the wings of Ca II H. Do you find any regions in the line wings that are not covered by blends?","title":"Formation of Mg II lines"},{"location":"MgII_formation/#formation-of-mg-ii-lines","text":"In this exercise we will explore the formation of Mg II lines. You should have completed (or understood) the previous Ca II example to work on this one. The objective of this exercise is to synthesise the spectral region corresponding to the NUV window of the IRIS spectrograph, including the Mg II lines but also the many blended lines.","title":"Formation of Mg II lines"},{"location":"MgII_formation/#setup","text":"In your run directory, we'll use almost the same setup as for the Ca II exercise. First, you need to modify atoms.input and set the MgII-IRIS.atom as ACTIVE (and all other atoms as PASSIVE ). Now, because we changed the active atom, the wavelengths written to file will be different. This means that the wavelength indices we previously wrote in ray.input no longer match what we expected. For simplicity, in this exercise we can use a simple ray.input that writes no extra output. You can create a ray.input file with only the following: 1.00 0 The Mg II h & k lines are formed under partial redistribution (PRD). PRD is a complex topic and is not taught in this introductory course. But for this exercise you only need to activate it in RH. In your keyword.input file, find the option PRD_N_MAX_ITER . This should be set to zero. Now change it to PRD_N_MAX_ITER = 3 , and you will activate PRD for atoms that require it. Now run rh15d_ray with that setup and look at the intensity in the region of 279 - 280.5 nm, where the Mg II lines are located. How many wavelength points does the intensity have?","title":"Setup"},{"location":"MgII_formation/#wavelength-files","text":"The wavelengths that RH 1.5D uses depend on the active model atoms. In the atom file you can configure the number of wavelength points that each transition has, as well as how they are distributed. For bound-bound transitions, the parameter Nlambda defines how many wavelength points they have. This is the most straightforward way to change the wavelength grid. In addition to changing the atom files, there is another mechanism to add more wavelengths: the wavelength files. These files contain a list of additional wavelengths for RH to calculate. They are useful when you want to add lines from lists (see below) that are not covered by the active atoms, when you want to add more wavelengths to a specific line or region, or when you want better control over the wavelength grid.","title":"Wavelength files"},{"location":"MgII_formation/#using-wavelength-files","text":"Only one wavelength file (or wavelength table) is allowed in RH. To use a wavelength file, you need to set the option WAVETABLE equal to the wavelength file. Edit your keyword.input file so that WAVETABLE = ../../Atoms/wave_files/IRIS_NUV_full.wave . This file contains a list of the IRIS NUV wavelengths, and if you've previously unpacked the archive rh_ast5210.tar.bz2 , it should be in that directory. Run rh15d_ray again with that new option. How many wavelength files were used now? You should also have noticed that the calculation took much longer now because it scales with the number of wavelengths.","title":"Using wavelength files"},{"location":"MgII_formation/#reading-and-writing-wavelength-files","text":"The wavelength files are written in binary XDR format . In helita there are functions to read and write these files. Info The contents of the wavelength files should be in vacuum wavelengths, and in nm. RH uses vacuum wavelengths internally, although by default all the output for \\lambda \\lambda > 200 nm will be given in air wavelengths. To read an existing an existing wavelength file, use the function helita.sim.rh15d.read_wave_file : IRIS_wave = rh15d . read_wave_file ( '/Users/tiago/codes/rh/Atoms/wave_files/IRIS_NUV_full.wave' ) Now check the content of that IRIS wavelength file. What is the wavelength separation? To write a wavelength file, you use the function helita.sim.rh15d.make_wave_file : # this will write wavelenghts from 650 to 650 nm, 0.01 nm spacing rh15d . make_wave_file ( 'my.wave' , 650 , 660 , 0.01 ) # this will write an existing array \"my_waves\", if it exists rh15d . make_wave_file ( 'my.wave' , new_wave = my_waves ) By default, make_wave_file will assume your wavelengths are in air and convert to vacuum wavelengths. If you don't want this, use the option air=False . Create a new wavelength file with the same range of wavelengths as in the IRIS file, but with a spacing of 0.001 nm. We'll use this file in the exercises below. When you run with a large wavelength file, RH can take a long time to finish. How to check if RH is indeed running properly? In the run directory there is a subdirectory called scratch . Inside, you can find a lot of temporary scratch files ( *.dat ), and also log files ( rh_p*.log ). Each process writes its own log file. Because you've been running rh15d_ray with only one process, there should only be one file called rh_p0.log . This file is updated as RH is running. If RH is running and you want to check if it's actually doing anything, you can follow that file with tail: $ tail -f output/scratch/rh_p0.log","title":"Reading and writing wavelength files"},{"location":"MgII_formation/#line-lists","text":"Now that you've calculated the spectrum, you'll see that it only contains the lines of Mg II (the active atom). Adding extra wavelengths from the file does not change that. We'd like to make this as realistic as possible and include as many lines as possible. The most correct way to do this is to include atoms of relevant elements with all the necessary transitions and calculate all spectra in NLTE. Unfortunately, this would require a very large number of atoms and at least hundreds of thousands of transitions, requiring many wavelength points and RH 1.5D would probably not finish before you are done with AST5210. A simpler and much faster option is to calculate those lines in LTE and use a line list. Again, LTE is probably not a good approximation for many of the strong spectral lines, but this a tradeoff that we'll have to live with. A line list is a file with a list of bound-bound transitions and their parameters. RH supports line lists with the format of the Kurucz line lists . In this format, each line in the file is a different spectral line. The various columns have different atomic data, starting with wavelength, log gf, and element code (see Kurucz page for more details). To use a line list with RH, you will need to uncomment the setting KURUCZ_DATA = kurucz.input in keyword.input . This merely points to a text file (in this case we use kurucz.input ) that has a list of line list files. Uncomment that line, and edit the file kurucz.input . You can start by using only a single entry: ../../Atoms/Kurucz/gfMgIIhk_IRIS_full If you've previously unpacked the archive rh_ast5210.tar.bz2 , the file above should be in your RH directory. It contains 3714 lines that are present in the wavelength region 278.1745 - 283.4151 nm. Run rh15d_ray again with the line list, the wavelength file IRIS_NUV_full.wave and inspect the results. Run timings with the shell command time and see how much more time it takes to include the wavelength file, and both the line lists. Included in your rh/Atoms/Kurucz/ is another line list called gfMgIIhk_IRIS_full.trim_85 . This file containts a subset of the gfMgIIhk_IRIS_full . It was made to approximate the full line list but only keeping the strongest lines (around the 85 th percentile of line strength). Run with this new file and see if you can see a difference in the output intensity. You may notice that the extra lines do not appear very well resolved (e.g. triangular shapes). This is because the file IRIS_NUV_full.wave only has enough wavelength points to cover the spatial resolution of IRIS, and was not meant for detailed analysis of individual lines. Now run RH again but with the wavelength file you created (separation 0.001 nm), and see if the lines are better resolved now. How many wavelengths were calculated?","title":"Line lists"},{"location":"MgII_formation/#tautau1-heights","text":"In the exercises above we are not saving detailed output, so we don't have the total absorption (chi) that is necessary to calculate the optical depth. However, even without detailed output it is possible to save an additional quantity that helps us diagnose approximately where the line is formed: the height where the optical depth reaches unity. In keyword.input you need to set 15D_WRITE_TAU1 = TRUE (it should not be enabled by default). Re-run RH and you'll find that the output_ray.hdf5 has an additional output variable called tau_one_height . The variable tau_one_height , just like intensity , is a function of wavelength. Plot it as a function of wavelength. You can also plot the intensity separately. Which line is formed higher? What is the difference in \\tau \\tau =1 height between the Mg II h & k lines with your model atmosphere? Aside from the Mg II lines, which other lines are formed higher?","title":"\\tau\\tau=1 heights"},{"location":"MgII_formation/#putting-it-all-together","text":"Now we'll put the above concepts together by applying them to the Ca II H line (air wavelength 396.847 nm): Run rh15d_ray using the CaII_PRD.atom as active atom (Mg II can be passive) Create a new wavelength file to adequately sample all the blending lines on the wings of Ca II H. Choose an appropriate spacing. Use the file rh/Atoms/Kurucz/gf0400.10 as a starting point to create a line list to cover the wavelength range of the Ca II H line. Just delete all the lines whose wavelengths are outside the range. Run RH with and without the new wavelengths/lines in the wings of Ca II H. Do you find any regions in the line wings that are not covered by blends?","title":"Putting it all together"},{"location":"running/","text":"Running RH 1.5D \u00b6 Auxiliary files \u00b6 The RH 1.5D distribution that you obtained from Github does not contain all the files necessary for this course. Please download an additional archive and unpack it in the RH main folder: $ tar jxvf rh_ast5210.tar.bz2 This will place all files in their correct directories. Quickstart: running and looking at output \u00b6 You should run the code in a run directory. When you get the source, there should be a directory under rh/rh15d/run_example . You can copy this directory to your own so you can make your changes: $ cp -rp run_example run $ cd run Once inside run , there are already some input files and directories. You can do a test run of RH by doing: ../rh15d_ray By default this will run with only one processor, and an example calculation with a Ca atom. You can read a lot more detail into the input files and running options in the documentation. Inside your run directory go through the different tasks: Run the different binaries: rh15d_ray , rh15d_ray_pool , rh15d_lteray . What happens if you run rh15d_ray_pool without calling mpiexec or mpirun ? Explore the output files in the command line with ncdump -h or h5dump -H . Using Jupyter notebooks \u00b6 You can have a look at the RH 1.5D sample notebooks under rh/doc/notebooks/ . For the work in these exercises, it is recommend it that you run jupyter from a directory of your chosing, ideally where you have output files from RH (e.g. the directory output/ inside your run directory). The notebook source files ( *.ipynb ) will be saved there. Once in the jupyter starting page, select \"New\" and then \"Python 3\". In the first cell, add the boilerplate code mentioned earlier: % matplotlib widget import numpy as np import matplotlib.pyplot as plt from helita.sim import rh15d , rh15d_vis And now you are ready to start playing with RH. Exploring input atmospheres \u00b6 Your default keyword.input file uses the FALC_82_5x5.hdf5 atmosphere file, which is a FAL C atmosphere converted to HDF5 format and replicated to 5x5 columns in 3D. All columns have the same information. Under the directory rh/Atmos you will also find a file called bifrost_cb24bih_s385_cut.hdf5 , which is a cut from a 3D simulation from Bifrost. You can explore both with the rh15d_vis.InputAtmosphere procedure. You need to pass the filename of an atmosphere file as argument: rh15d_vis . InputAtmosphere ( 'MY_ATMOS_DIR/Atmos/FALC_82_5x5.hdf5' ); Replace MY_ATMOS_DIR with the directory where you have the RH atmospheres (typically in rh/Atmos ). You can give relative or absolute paths. Exploring the output \u00b6 If you are in a directory with the output files of RH, you can simply enter the following to load the data: data = rh15d . Rh15dout () If your output files are in a different directory, pass that directory as an argument to Rh15dout() . Once you have the output loaded, a simple inspection of the intensity can be made with: fig , ax = plt . subplots () data . ray . intensity . plot () By default this will show all calculated wavelengths, but you can zoom in to a line of interest with matplotlib's interactive figure.","title":"Running RH 1.5D"},{"location":"running/#running-rh-15d","text":"","title":"Running RH 1.5D"},{"location":"running/#auxiliary-files","text":"The RH 1.5D distribution that you obtained from Github does not contain all the files necessary for this course. Please download an additional archive and unpack it in the RH main folder: $ tar jxvf rh_ast5210.tar.bz2 This will place all files in their correct directories.","title":"Auxiliary files"},{"location":"running/#quickstart-running-and-looking-at-output","text":"You should run the code in a run directory. When you get the source, there should be a directory under rh/rh15d/run_example . You can copy this directory to your own so you can make your changes: $ cp -rp run_example run $ cd run Once inside run , there are already some input files and directories. You can do a test run of RH by doing: ../rh15d_ray By default this will run with only one processor, and an example calculation with a Ca atom. You can read a lot more detail into the input files and running options in the documentation. Inside your run directory go through the different tasks: Run the different binaries: rh15d_ray , rh15d_ray_pool , rh15d_lteray . What happens if you run rh15d_ray_pool without calling mpiexec or mpirun ? Explore the output files in the command line with ncdump -h or h5dump -H .","title":"Quickstart: running and looking at output"},{"location":"running/#using-jupyter-notebooks","text":"You can have a look at the RH 1.5D sample notebooks under rh/doc/notebooks/ . For the work in these exercises, it is recommend it that you run jupyter from a directory of your chosing, ideally where you have output files from RH (e.g. the directory output/ inside your run directory). The notebook source files ( *.ipynb ) will be saved there. Once in the jupyter starting page, select \"New\" and then \"Python 3\". In the first cell, add the boilerplate code mentioned earlier: % matplotlib widget import numpy as np import matplotlib.pyplot as plt from helita.sim import rh15d , rh15d_vis And now you are ready to start playing with RH.","title":"Using Jupyter notebooks"},{"location":"running/#exploring-input-atmospheres","text":"Your default keyword.input file uses the FALC_82_5x5.hdf5 atmosphere file, which is a FAL C atmosphere converted to HDF5 format and replicated to 5x5 columns in 3D. All columns have the same information. Under the directory rh/Atmos you will also find a file called bifrost_cb24bih_s385_cut.hdf5 , which is a cut from a 3D simulation from Bifrost. You can explore both with the rh15d_vis.InputAtmosphere procedure. You need to pass the filename of an atmosphere file as argument: rh15d_vis . InputAtmosphere ( 'MY_ATMOS_DIR/Atmos/FALC_82_5x5.hdf5' ); Replace MY_ATMOS_DIR with the directory where you have the RH atmospheres (typically in rh/Atmos ). You can give relative or absolute paths.","title":"Exploring input atmospheres"},{"location":"running/#exploring-the-output","text":"If you are in a directory with the output files of RH, you can simply enter the following to load the data: data = rh15d . Rh15dout () If your output files are in a different directory, pass that directory as an argument to Rh15dout() . Once you have the output loaded, a simple inspection of the intensity can be made with: fig , ax = plt . subplots () data . ray . intensity . plot () By default this will show all calculated wavelengths, but you can zoom in to a line of interest with matplotlib's interactive figure.","title":"Exploring the output"}]}